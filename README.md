# Computer Vision for FOD

Leveraging computer vision to aid in foreign object detection in a manufacturing setting.

Before beginning to work on this project, it is important to be familiar with git. A brief git tutorial can be found [here](https://github.com/JLZ22/Git-Tutorial-for-New-Users).

It is also **STRONGLY RECOMMENDED** that you work in a python virtual environment. One option is to use python3's built in [venv](https://docs.python.org/3/library/venv.html) while another is to use [conda](https://conda.io/projects/conda/en/latest/user-guide/install/index.html) and its [virtual environment manager](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html). I (John Zeng, B.S. AI + Computer Science at Purdue, 2026) recommend using python3's built in venv because it is more lightweight than conda. **When using virtual environments, be sure to include those in the `.gitignore`. You can read more about them in the git tutorial above.** This project was developed using `Python3.12`.

## Package List

```
ultralytics
opencv-python
imgaug 
numpy 
pascal_voc
pascal_voc_writer 
pascal-voc-tools
tqdm
matplotlib
clearml
pdoc
```

To install using `pip`, run `pip install -r requirements.txt`. For proper functionality of `clearml` (optional), make an [account](https://app.clear.ml/login) and follow setup instructions. 

### Package Issues

- `ultralytics` and `pytorch` may have some dependency issues. A solution that was found to work is to downgrade `pytorch` to `2.3.1` instead of `2.4.0` and reinstall `torchvision` with a version that is compatible with `pytorch==2.3.1`.

## Documentation

To find current API documentation of the main branch, please visit this [page](https://jlz22.github.io/Computer-Vision-for-FOD/index.html) which has been generated by [pdoc](https://pdoc.dev/). To use `pdoc` to generate documentation for a different `*.py` file (in the case that you are working off/on a different branch), you can run `pdoc <file1.py> [file2.py ...]` which will start a web server and open a automatically. When creating new `*.py` files, please ensure that they are documented such that `pdoc` formats it well. 

## Augmentation Notes

[imgaug](https://github.com/aleju/imgaug?tab=readme-ov-file) is an open source software that aids in image augmentation. We will be using that to augment our training and test images.

Images were subject to the following augmentations in random order for training. 
- vertical/horizontal flips
- random crops between 0% and 10% of the image
- Gaussian Blur (applied 50% of the time)
- strengthenning or weakenning contrast between 75% and 150% the original value
- Gaussian Noise (applied 50% of the time)
- randomly adjust brightness between 80% and 120% the original value for 20% of images
- Randomly zoomed, or translated

After augmentation, for each image in the dataset, the mean pixel value per channel is subtracted from it according to the 7th source in the literature review section.

In a random sample of 128 data points, we found that 4 data points were faulty. Using a one sample t-test, we concluded with 99% confidence that 0.084% and 7.09% of the dataset of 10,048 images are faulty.

### Note for using augmentation modules:

Be **very careful** when augmenting with **high resolution images** because it can be memory intensive and **crash** your computer. **ALWAYS**, resize your images to sub-1k dimensions before attempting augmentation.

## Todo

- [x] find solution to memory issue
- [x] finish augmenting rest of the classes
- [x] resize images and corresponding bounding boxes
- [x] transform labels from PascalVOC to YOLO 
- [x] rename labels for consistency
- [x] subtract mean pixel value from all images 
- [x] partition data into training and validation
- [x] separate txt and jpg
- [x] train on augmented data
- [x] train on unaugmented data
- [x] use tracking to highlight objects that are within a roi for a certain duration
- [x] find most effective standard for determining if an object is in the roi or not
- [x] keep objects highlighted if they leave the roi briefly
- [ ] test in assembly space on 1 camera
- [ ] test in assembly space on 3 cameras

## Info about dataset version 1

- Post augmentation labels per class: 
    - `allen wrench:` 4608 labels
    - `pencil:` 17728 labels
    - `screwdriver:` 5120 labels
    - `tool bit:` 10688 labels
    - `wrench:` 10624 labels
    - `total:` 48768 labels

- Pre augmentation labels per class: 
    - `allen wrench:` 72 labels
    - `pencil:` 277 labels
    - `screwdriver:` 80 labels
    - `tool bit:` 167 labels
    - `wrench:` 166 labels
    - `total: ` 762 labels

- Normalized labels per class: 
    - `allen wrench:` 0.094
    - `pencil:` 0.364 
    - `screwdriver:` 0.105 
    - `tool bit:` 0.219 
    - `wrench:` 0.218 

## Literature Review

1. (March 2024) [Small-Scale Foreign Object Debris Detection Using Deep Learning and Dual Light Modes](https://www.mdpi.com/2076-3417/14/5/2162)
2. (February 2024) [A two-stage deep learning method for foreign object detection and localization](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13069/130690G/A-two-stage-deep-learning-method-for-foreign-object-detection/10.1117/12.3024079.full#_=_)
3. (July 2023) [A doubtâ€“confirmation-based visual detection method for foreign object debris aided by assembly models](https://cdnsciencepub.com/doi/full/10.1139/tcsme-2022-0143)
4. (Sept 2022)[Foreign Object Detection on an Assembly Line](https://link.springer.com/content/pdf/10.1007/978-981-19-2600-6_29.pdf)
5. (June 2022) [Foreign objects detection using deep learning techniques for graphic card assembly line](https://link.springer.com/article/10.1007/s10845-022-01980-7)
6. (April 2020) [Deep Learning Models for Visual Inspection on Automotive Assembling Line](https://arxiv.org/ftp/arxiv/papers/2007/2007.01857.pdf)
7. (July 2019) [Best Practices for Preparing and Augmenting Image Data for CNNs](https://machinelearningmastery.com/best-practices-for-preparing-and-augmenting-image-data-for-convolutional-neural-networks/)
8. (September 2012) [Practical Recommendations for Gradient-Based Training of Deep
Architectures](https://arxiv.org/pdf/1206.5533)